{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.17754124741145427\n",
      "Validation Accuracy after epoch 1: 97.67%\n",
      "Epoch 2, Loss: 0.08484521786967221\n",
      "Validation Accuracy after epoch 2: 97.42%\n",
      "Test Accuracy: 97.97%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        PRON       0.93      0.99      0.96       208\n",
      "         AUX       1.00      0.98      0.99       234\n",
      "         DET       1.00      0.98      0.99       428\n",
      "        NOUN       0.97      0.99      0.98       933\n",
      "         ADP       1.00      0.98      0.99      1421\n",
      "       PROPN       0.99      0.99      0.99      1232\n",
      "        VERB       0.96      0.98      0.97       440\n",
      "         NUM       0.96      0.91      0.94       114\n",
      "         ADJ       0.94      0.89      0.91       185\n",
      "       CCONJ       0.99      1.00      1.00       107\n",
      "         ADV       0.76      0.64      0.70        45\n",
      "        PART       0.93      0.98      0.96        56\n",
      "        INTJ       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.98      5408\n",
      "   macro avg       0.96      0.95      0.95      5408\n",
      "weighted avg       0.98      0.98      0.98      5408\n",
      "\n",
      "[[ 206    0    1    0    0    0    0    1    0    0    0    0    0]\n",
      " [   1  229    0    0    0    1    2    0    0    0    1    0    0]\n",
      " [   3    0  421    1    1    0    1    0    1    0    0    0    0]\n",
      " [   0    0    0  925    0    5    3    0    0    0    0    0    0]\n",
      " [  12    0    0    0 1399    0    3    0    1    0    2    4    0]\n",
      " [   0    0    0    4    0 1222    3    1    1    0    1    0    0]\n",
      " [   0    0    0    5    0    2  432    1    0    0    0    0    0]\n",
      " [   0    1    0    4    0    1    3  104    1    0    0    0    0]\n",
      " [   0    0    0   10    0    3    2    1  164    0    5    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0  107    0    0    0]\n",
      " [   0    0    0    2    2    4    1    0    6    1   29    0    0]\n",
      " [   0    0    0    0    1    0    0    0    0    0    0   55    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    5]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from FFNN_runner import FFNNRunner\n",
    "from LSTM_runner import LSTMRunner\n",
    "\n",
    "# if len(sys.argv) != 2:\n",
    "#     print(\"Usage: python pos_tagger.py <model_flag>\")\n",
    "#     sys.exit(1)\n",
    "    \n",
    "model_flag = sys.argv[1]\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "NUM_EPOCHS = 2\n",
    "BATCH_SIZE = 1\n",
    "NUM_LAYERS = 1\n",
    "\n",
    "file_paths = \"UD_English-Atis/en_atis-ud-\"\n",
    "\n",
    "trainer = None\n",
    "\n",
    "# if model_flag == \"-f\":\n",
    "trainer = FFNNRunner(\n",
    "    train_file=file_paths + \"train.conllu\",\n",
    "    val_file=file_paths + \"dev.conllu\",\n",
    "    test_file=file_paths + \"test.conllu\",\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    pre=1,\n",
    "    suc=1,\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "trainer.train_model()\n",
    "trainer.test_model()\n",
    "        \n",
    "# elif model_flag == \"-r\":\n",
    "#     trainer = LSTMRunner(\n",
    "#         train_file=file_paths + \"train.conllu\",\n",
    "#         val_file=file_paths + \"dev.conllu\",\n",
    "#         test_file=file_paths + \"test.conllu\",\n",
    "#         embedding_dim=EMBEDDING_DIM,\n",
    "#         hidden_dim=HIDDEN_DIM,\n",
    "#         num_epochs=NUM_EPOCHS,\n",
    "#         batch_size=BATCH_SIZE,\n",
    "#         num_layers=NUM_LAYERS\n",
    "#     )\n",
    "#     trainer.train_model()\n",
    "#     trainer.test_model()\n",
    "    \n",
    "# else:\n",
    "#     print(\"Usage: model_flag must be -f or -r.\")\n",
    "#     sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to fly from Boston at 838 am and arrive in Denver at 1110 in the morning\n",
      "['I', 'want', 'to', 'fly', 'from', 'Boston', 'at', '838', 'am', 'and', 'arrive', 'in', 'Denver', 'at', '1110', 'in', 'the', 'morning']\n",
      "[863, 212, 11, 38, 9, 863, 257, 650, 141, 18, 70, 29, 863, 257, 651, 29, 2, 64]\n",
      "[]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# while True:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# sentence = input(\"Enter a sentence: \")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# if sentence == \"exit\":\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#     break\u001b[39;00m\n\u001b[1;32m      5\u001b[0m sentence_or \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI want to fly from Boston at 838 am and arrive in Denver at 1110 in the morning\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_or\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/sem6/inlp/assignment-2/FFNN_runner.py:106\u001b[0m, in \u001b[0;36mFFNNRunner.predict\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    104\u001b[0m inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([ele \u001b[38;5;28;01mfor\u001b[39;00m ele \u001b[38;5;129;01min\u001b[39;00m sentence])\n\u001b[1;32m    105\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(inputs)\n\u001b[0;32m--> 106\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_process_train\u001b[38;5;241m.\u001b[39mget_tags_from_ix(predicted\u001b[38;5;241m.\u001b[39mitem())]\n",
      "File \u001b[0;32m~/Documents/sem6/inlp/assignment-2/data_process.py:138\u001b[0m, in \u001b[0;36mdata_process_ffnn_sentence\u001b[0;34m(data, P, S)\u001b[0m\n\u001b[1;32m    136\u001b[0m     X\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mtensor([data[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(j \u001b[38;5;241m-\u001b[39m P, j \u001b[38;5;241m+\u001b[39m S \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]))\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mprint\u001b[39m(X)\n\u001b[0;32m--> 138\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "# while True:\n",
    "    # sentence = input(\"Enter a sentence: \")\n",
    "    # if sentence == \"exit\":\n",
    "    #     break\n",
    "sentence_or = \"I want to fly from Boston at 838 am and arrive in Denver at 1110 in the morning\"\n",
    "print(trainer.predict(sentence_or))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
